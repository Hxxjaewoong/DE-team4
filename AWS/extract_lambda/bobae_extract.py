import requests
from bs4 import BeautifulSoup
import json
import boto3
import datetime
import time
import random
import re
import html

# AWS ì„¤ì •
s3 = boto3.client('s3')
lambda_client = boto3.client('lambda')

# í™˜ê²½ ë³€ìˆ˜
BUCKET_NAME = "hmg5th-4-bucket"
RAW_HTML_PREFIX = "raw_html/bobae/"
LOGGING_LAMBDA_ARN = "arn:aws:lambda:ap-northeast-2:473551908409:function:crawling_log_lambda"

# ëª¨ë¸ ì •ì˜(í‚¤ì›Œë“œ í™•ì¥)
MODEL = {
    "palisade": ["í ë¦¬", "íŒ°ë¦¬"],
    "tucson": ["íˆ¬ì‹¼"],
    "ioniq9": ["ì•„ì´ì˜¤ë‹‰9", "ì˜¤ë‹‰9"],
    "avante": ["ì•„ë°˜ë–¼", "ì•„ë°©"]
}

TODAY = datetime.datetime.utcnow().date()
END_TIME = datetime.datetime.combine(TODAY - datetime.timedelta(days=1), datetime.time(0, 0, 0))

# ê¸°ë³¸ URL ë° ìš”ì²­ í—¤ë”
BASE_URL = "https://www.bobaedream.co.kr/search"
HEADERS = {
    "User-Agent": random.choice([
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36"
    ]),
    "Referer": BASE_URL,
    "Content-Type": "application/x-www-form-urlencoded"
}

# ìš”ì²­ ì¬ì‹œë„ í•¨ìˆ˜
def request_with_retries(url, method="GET", data=None, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = requests.post(url, headers=HEADERS, data=data, timeout=10) if method == "POST" else requests.get(url, headers=HEADERS, timeout=10)
            if response.status_code == 200:
                return response
            print(f"âš ï¸ ìš”ì²­ ì‹¤íŒ¨ {attempt + 1}/{max_retries} (ìƒíƒœ ì½”ë“œ: {response.status_code})")
        except requests.RequestException as e:
            print(f"âš ï¸ ìš”ì²­ ì˜¤ë¥˜ {attempt + 1}/{max_retries}: {str(e)}")
        time.sleep(2)
    log_error("request_with_retries", url, "ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
    return None

# ì—ëŸ¬ ë¡œê·¸ ì „ì†¡ í•¨ìˆ˜
def log_error(stage, url, error_message):
    log_payload = {
        "status": "error",
        "source": "bobae_extract",
        "stage": stage,
        "url": url,
        "error": error_message
    }
    lambda_client.invoke(
        FunctionName=LOGGING_LAMBDA_ARN,
        InvocationType="Event",
        Payload=json.dumps(log_payload)
    )

def lambda_handler(event, context):
    html_data = {}
    print(f"ğŸ“† í¬ë¡¤ë§ ê¸°ê°„: {END_TIME} ~ {TODAY}")
    
    # Step Functionì—ì„œ ì „ë‹¬ëœ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
    keywords = event.get("keywords", [])
    if not keywords:
        log_error("lambda_handler", url, "í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ê°€ ì…ë ¥ë˜ì§€ ì•ŠìŒ")
        print("âŒ í‚¤ì›Œë“œê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return {"status": "No Keywords Provided"}
    
    for keyword in keywords:
        print(f"ğŸ“¡ '{keyword}' í‚¤ì›Œë“œ í¬ë¡¤ë§ ì‹œì‘...")
        related_keywords = MODEL[keyword]
      
        
        for sub_keyword in related_keywords:
            print(f"ğŸ“¡ sub: '{sub_keyword}' í‚¤ì›Œë“œ í¬ë¡¤ë§ ì‹œì‘...")
            page = 1
            stop_flag = False

            while not stop_flag:
                print(f"ğŸ“„ í˜ì´ì§€ {page} í¬ë¡¤ë§ ì¤‘...")
                payload = {"keyword": sub_keyword, "searchField": "ALL", "colle": "community", "page": page}
                response = request_with_retries(BASE_URL, method="POST", data=payload)
                if not response:
                    break

                # ğŸ”¹ ì‘ë‹µ ì¸ì½”ë”© ë³€í™˜
                response.encoding = response.apparent_encoding
                soup = BeautifulSoup(response.text, "html.parser")
                posts = soup.select("div.search_Community ul li dt a")
                if not posts:
                    print("âœ… ë” ì´ìƒ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
                    break

                for post in posts:
                    post_url = "https://www.bobaedream.co.kr" + post["href"]
                    post_response = request_with_retries(post_url)
                    if not post_response:
                        continue

                    post_response.encoding = post_response.apparent_encoding
                    post_soup = BeautifulSoup(post_response.text, "html.parser")
                    count_group_tag = post_soup.select_one("span.countGroup")
                    count_group_text = count_group_tag.get_text(strip=True)
                    
                    date_match = re.search(r"(\d{4}\.\d{2}\.\d{2})\s*\(.*?\)\s*(\d{2}:\d{2})", count_group_text)
                    if date_match:
                        post_date = date_match.group(1).replace('.', '-')
                        post_time = date_match.group(2)
                        post_datetime = datetime.datetime.strptime(f"{post_date} {post_time}:00", "%Y-%m-%d %H:%M:%S")
                    else:
                        print(f"âŒ ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {count_group_text}")
                        continue
                    
                    if post_datetime < END_TIME:
                        print("âœ… í¬ë¡¤ë§ ê¸°ê°„ ì´ˆê³¼. ì¢…ë£Œ.")
                        stop_flag = True
                        break
                    
                    content_tag = post_soup.select_one("div.viewbg02")
                    if not content_tag:
                        log_error("lambda_handler", post_url, "viewbg02 íƒœê·¸ ì—†ìŒ")
                        continue
                    
                    content_text = html.unescape(content_tag.prettify())
                    html_data[post_url] = {"keyword": keyword, "html": content_text}
                
                if not stop_flag:
                    page += 1
                    time.sleep(1)
          
    
    if html_data:
        today_str = TODAY.strftime("%Y-%m-%d")
        file_key = f"{RAW_HTML_PREFIX}{today_str}.json"
        s3.put_object(
            Bucket=BUCKET_NAME,
            Key=file_key,
            Body=json.dumps(html_data, ensure_ascii=False, indent=4).encode("utf-8-sig"),
            ContentType="application/json; charset=utf-8"
        )
        print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! ë°ì´í„° ì €ì¥ë¨: {file_key}")
    else:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    return {"status": "Crawling completed"}
